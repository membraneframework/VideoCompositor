"use strict";(self.webpackChunkcompositor_live=self.webpackChunkcompositor_live||[]).push([[553],{7762:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>d,toc:()=>l});var i=r(5893),t=r(1151);const s={},o=void 0,d={id:"api/generated/renderer-RegisterInputRequest",title:"renderer-RegisterInputRequest",description:"RegisterInputRequest",source:"@site/pages/api/generated/renderer-RegisterInputRequest.md",sourceDirName:"api/generated",slug:"/api/generated/renderer-RegisterInputRequest",permalink:"/docs/api/generated/renderer-RegisterInputRequest",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{}},c={},l=[{value:"RegisterInputRequest",id:"registerinputrequest",level:2},{value:"Properties",id:"properties",level:4},{value:"Port",id:"port",level:2},{value:"Video",id:"video",level:2},{value:"Properties",id:"properties-1",level:4},{value:"Audio",id:"audio",level:2},{value:"Properties",id:"properties-2",level:4}];function a(e){const n={a:"a",code:"code",h2:"h2",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"registerinputrequest",children:"RegisterInputRequest"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"type RegisterInputRequest = {\n  input_id: string;\n  port: Port;\n  video?: Video;\n  audio?: Audio;\n}\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Parameters of registered RTP input stream. Before using input in video composition or output mixing, input has to be firstly registered using ",(0,i.jsx)(n.code,{children:"register_input"})," request."]}),"\n",(0,i.jsxs)(n.p,{children:["At least one of ",(0,i.jsx)(n.code,{children:"video"})," and ",(0,i.jsx)(n.code,{children:"audio"})," has to be defined."]}),"\n",(0,i.jsx)(n.h4,{id:"properties",children:"Properties"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"input_id"})," - An identifier for the input stream."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"port"})," - UDP port or port range on which the compositor should listen for the stream."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"video"})," - Parameters of a video source included in the RTP stream."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"audio"})," - Parameters of an audio source included in the RTP stream."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"port",children:"Port"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"type Port = string | u16\n"})}),"\n",(0,i.jsx)(n.h2,{id:"video",children:"Video"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'type Video = {\n  codec?: "h264";\n  rtp_payload_type?: u8;\n}\n'})}),"\n",(0,i.jsx)(n.h4,{id:"properties-1",children:"Properties"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"codec"})," - (",(0,i.jsxs)(n.strong,{children:["default=",(0,i.jsx)(n.code,{children:'"h264"'})]}),") Video codec.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:'"h264"'})," - H264 video."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"rtp_payload_type"})," - (",(0,i.jsxs)(n.strong,{children:["default=",(0,i.jsx)(n.code,{children:"96"})]}),") Value of payload type field in received RTP packets.\nPackets with different payload type won't be treated as video and included in composing. Values should be in [0, 64] or [96, 255]. Values in range [65, 95] can't be used. For more information, see ",(0,i.jsx)(n.a,{href:"https://datatracker.ietf.org/doc/html/rfc5761#section-4",children:"RFC"})," Packets with different payload type won't be treated as video and included in composing."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"audio",children:"Audio"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'type Audio = {\n  codec?: "opus";\n  sample_rate: u32;\n  channels: "mono" | "stereo";\n  rtp_payload_type?: u8;\n  forward_error_correction?: bool;\n}\n'})}),"\n",(0,i.jsx)(n.h4,{id:"properties-2",children:"Properties"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"codec"})," - (",(0,i.jsxs)(n.strong,{children:["default=",(0,i.jsx)(n.code,{children:'"opus"'})]}),") Audio codec.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:'"opus"'})," - Opus audio."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"sample_rate"})," - Sample rate. If the specified sample rate doesn't match real sample rate, audio won't be mixed properly."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"channels"})," - Audio channels.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:'"mono"'})," - Mono audio (single channel)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:'"stereo"'})," - Stereo audio (two channels)."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"rtp_payload_type"})," - (",(0,i.jsxs)(n.strong,{children:["default=",(0,i.jsx)(n.code,{children:"97"})]}),") Value of payload type field in received RTP packets.\nPackets with different payload type won't be treated as audio and included in mixing. Values should be in range [0, 64] or [96, 255]. Values in range [65, 95] can't be used. For more information, check out ",(0,i.jsx)(n.a,{href:"https://datatracker.ietf.org/doc/html/rfc5761#section-4",children:"RFC"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"forward_error_correction"})," - (",(0,i.jsxs)(n.strong,{children:["default=",(0,i.jsx)(n.code,{children:'"false"'})]}),") Specifies whether the stream uses forward error correction. It's specific for Opus codec. For more information, check out ",(0,i.jsx)(n.a,{href:"https://datatracker.ietf.org/doc/html/rfc6716#section-2.1.7",children:"RFC"}),"."]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(a,{...e})}):a(e)}},1151:(e,n,r)=>{r.d(n,{Z:()=>d,a:()=>o});var i=r(7294);const t={},s=i.createContext(t);function o(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);