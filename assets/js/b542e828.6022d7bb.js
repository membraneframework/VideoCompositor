"use strict";(self.webpackChunkcompositor_live=self.webpackChunkcompositor_live||[]).push([[935],{5237:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>d,default:()=>p,frontMatter:()=>i,metadata:()=>o,toc:()=>l});var t=r(5893),s=r(1151);const i={description:"API routes to configure the compositor."},d="Routes",o={id:"api/routes",title:"Routes",description:"API routes to configure the compositor.",source:"@site/pages/api/routes.md",sourceDirName:"api",slug:"/api/routes",permalink:"/docs/api/routes",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{description:"API routes to configure the compositor."},sidebar:"sidebar",previous:{title:"API Reference",permalink:"/docs/category/api-reference"},next:{title:"InputStream",permalink:"/docs/api/components/InputStream"}},c={},l=[{value:"Endpoint <code>POST /--/api</code>",id:"endpoint-post---api",level:2},{value:"Start",id:"start",level:3},{value:"Update scene",id:"update-scene",level:3},{value:"Register input stream",id:"register-input-stream",level:3},{value:"Port",id:"port",level:4},{value:"Video",id:"video",level:4},{value:"Audio",id:"audio",level:4},{value:"Register output stream",id:"register-output-stream",level:3},{value:"Register renderer",id:"register-renderer",level:3},{value:"Unregister request",id:"unregister-request",level:3},{value:"Endpoint <code>GET /status</code>",id:"endpoint-get-status",level:2}];function a(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"routes",children:"Routes"}),"\n",(0,t.jsxs)(n.p,{children:["API is served by default on the port 8081. Different port can be configured using ",(0,t.jsx)(n.a,{href:"../deployment/configuration#live_compositor_api_port",children:(0,t.jsx)(n.code,{children:"LIVE_COMPOSITOR_API_PORT"})})," environment variable."]}),"\n",(0,t.jsxs)(n.h2,{id:"endpoint-post---api",children:["Endpoint ",(0,t.jsx)(n.code,{children:"POST /--/api"})]}),"\n",(0,t.jsx)(n.p,{children:"Main endpoint for configuring the compositor server."}),"\n",(0,t.jsx)(n.h3,{id:"start",children:"Start"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'type Start = {\n  type: "start";\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"Starts the processing pipeline. If outputs are registered and defined in the scene then the compositor will start to send the RTP stream."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"update-scene",children:"Update scene"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'type UpdateScene = {\n  type: "update_scene";\n  outputs: OutputScene[];\n}\n\ntype OutputScene = {\n    output_id: string;\n    root: Component;\n}\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"outputs"})," - List of outputs. Identifies what should be rendered for each RTP output streams.","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"outputs[].output_id"})," - Id of an already registered output stream. See ",(0,t.jsx)(n.a,{href:"./routes#register-output-stream",children:(0,t.jsx)(n.code,{children:"RegisterOutputStream"})}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"outputs[].root"})," - Root of a component tree that should be rendered for the output. ",(0,t.jsx)(n.a,{href:"../concept/component",children:"Learn more"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"register-input-stream",children:"Register input stream"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'type RegisterInputStream = {\n  type: "register";\n  entity_type: "rtp_input_stream";\n  input_id: string;\n  port: Port;\n  video?: Video;\n  audio?: Audio;\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Parameters of registered RTP input stream. Before using input in video composition or output mixing, input has to be firstly registered using ",(0,t.jsx)(n.code,{children:"register_input"})," request."]}),"\n",(0,t.jsxs)(n.p,{children:["At least one of ",(0,t.jsx)(n.code,{children:"video"})," and ",(0,t.jsx)(n.code,{children:"audio"})," has to be defined."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"input_id"})," - An identifier for the input stream."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"port"})," - UDP port or port range on which the compositor should listen for the stream."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"video"})," - Parameters of a video source included in the RTP stream."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"audio"})," - Parameters of an audio source included in the RTP stream."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"port",children:"Port"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"type Port = string | u16\n"})}),"\n",(0,t.jsx)(n.h4,{id:"video",children:"Video"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'type Video = {\n  codec?: "h264";\n  rtp_payload_type?: u8;\n}\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"codec"})," - (",(0,t.jsxs)(n.strong,{children:["default=",(0,t.jsx)(n.code,{children:'"h264"'})]}),") Video codec.","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:'"h264"'})," - H264 video."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"rtp_payload_type"})," - (",(0,t.jsxs)(n.strong,{children:["default=",(0,t.jsx)(n.code,{children:"96"})]}),") Value of payload type field in received RTP packets.\nPackets with different payload type won't be treated as video and included in composing. Values should be in [0, 64] or [96, 255]. Values in range [65, 95] can't be used. For more information, see ",(0,t.jsx)(n.a,{href:"https://datatracker.ietf.org/doc/html/rfc5761#section-4",children:"RFC"})," Packets with different payload type won't be treated as video and included in composing."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"audio",children:"Audio"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'type Audio = {\n  codec?: "opus";\n  sample_rate: u32;\n  channels: "mono" | "stereo";\n  rtp_payload_type?: u8;\n  forward_error_correction?: bool;\n}\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"codec"})," - (",(0,t.jsxs)(n.strong,{children:["default=",(0,t.jsx)(n.code,{children:'"opus"'})]}),") Audio codec.","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:'"opus"'})," - Opus audio."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"sample_rate"})," - Sample rate. If the specified sample rate doesn't match real sample rate, audio won't be mixed properly."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"channels"})," - Audio channels.","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:'"mono"'})," - Mono audio (single channel)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:'"stereo"'})," - Stereo audio (two channels)."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"rtp_payload_type"})," - (",(0,t.jsxs)(n.strong,{children:["default=",(0,t.jsx)(n.code,{children:"97"})]}),") Value of payload type field in received RTP packets.\nPackets with different payload type won't be treated as audio and included in mixing. Values should be in range [0, 64] or [96, 255]. Values in range [65, 95] can't be used. For more information, check out ",(0,t.jsx)(n.a,{href:"https://datatracker.ietf.org/doc/html/rfc5761#section-4",children:"RFC"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"forward_error_correction"})," - (",(0,t.jsxs)(n.strong,{children:["default=",(0,t.jsx)(n.code,{children:"false"})]}),") Specifies whether the stream uses forward error correction. It's specific for Opus codec. For more information, check out ",(0,t.jsx)(n.a,{href:"https://datatracker.ietf.org/doc/html/rfc6716#section-2.1.7",children:"RFC"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"register-output-stream",children:"Register output stream"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'type RegisterOutputStream = {\n  type: "register";\n  entity_type: "output_stream";\n  output_id: string;\n  port: u16;\n  ip: string;\n  resolution: {\n    width: number;\n    height: number;\n  };\n  encoder_preset?: EncoderPreset; \n}\n\ntype EncoderPreset =\n  | "ultrafast"\n  | "superfast"\n  | "veryfast"\n  | "faster"\n  | "fast"\n  | "medium"\n  | "slow"\n  | "slower"\n  | "veryslow"\n  | "placebo"\n'})}),"\n",(0,t.jsx)(n.p,{children:"Register a new RTP output stream."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"output_id"})," - An identifier for the output stream. It can be used in the ",(0,t.jsx)(n.code,{children:"UpdateScene"})," request to define what to render for the output stream."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"port"})," / ",(0,t.jsx)(n.code,{children:"ip"})," - UDP port and IP where compositor should send the stream."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"resolution"})," - Output resolution in pixels."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"encoder_preset"})," - (",(0,t.jsxs)(n.strong,{children:["default=",(0,t.jsx)(n.code,{children:'"fast"'})]}),") Preset for an encoder. See ",(0,t.jsx)(n.code,{children:"FFmpeg"})," ",(0,t.jsx)(n.a,{href:"https://trac.ffmpeg.org/wiki/Encode/H.264#Preset",children:"docs"})," to learn more."]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"register-renderer",children:"Register renderer"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'type RegisterRenderer = {\n  type: "register";\n  entity_type: "shader" | "web_renderer" | "image";\n  ... // renderer specific options\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"See renderers documentation to learn more."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"./renderers/image",children:"Image"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"./renderers/shader",children:"Shader"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"./renderers/web",children:"WebRenderer"})}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"unregister-request",children:"Unregister request"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'type Unregister =\n  | { type: "unregister", entity_type: "input_stream", input_id: string }\n  | { type: "unregister", entity_type: "output_stream", output_id: string }\n  | { type: "unregister", entity_type: "shader", shader_id: string }\n  | { type: "unregister", entity_type: "image", image_id: string }\n  | { type: "unregister", entity_type: "web_renderer", instance_id: string }\n'})}),"\n",(0,t.jsxs)(n.h2,{id:"endpoint-get-status",children:["Endpoint ",(0,t.jsx)(n.code,{children:"GET /status"})]}),"\n",(0,t.jsxs)(n.p,{children:["Status/health check endpoint. Returns ",(0,t.jsx)(n.code,{children:"200 OK"}),"."]})]})}function p(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}},1151:(e,n,r)=>{r.d(n,{Z:()=>o,a:()=>d});var t=r(7294);const s={},i=t.createContext(s);function d(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);