"use strict";(self.webpackChunkcompositor_live=self.webpackChunkcompositor_live||[]).push([[2692],{4011:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>c,contentTitle:()=>s,default:()=>a,frontMatter:()=>o,metadata:()=>d,toc:()=>l});var t=n(5893),i=n(1151);const o={},s=void 0,d={id:"api/generated/renderer-RtpInputStream",title:"renderer-RtpInputStream",description:"RtpInputStream",source:"@site/pages/api/generated/renderer-RtpInputStream.md",sourceDirName:"api/generated",slug:"/api/generated/renderer-RtpInputStream",permalink:"/docs/api/generated/renderer-RtpInputStream",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{}},c={},l=[{value:"RtpInputStream",id:"rtpinputstream",level:2},{value:"Properties",id:"properties",level:4},{value:"InputRtpVideoOptions",id:"inputrtpvideooptions",level:2},{value:"Properties",id:"properties-1",level:4},{value:"InputRtpAudioOptions",id:"inputrtpaudiooptions",level:2},{value:"Properties",id:"properties-2",level:4}];function p(e){const r={a:"a",code:"code",h2:"h2",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.h2,{id:"rtpinputstream",children:"RtpInputStream"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-typescript",children:'type RtpInputStream = {\n  port: string | u16;\n  transport_protocol?: "udp" | "tcp_server";\n  video?: InputRtpVideoOptions;\n  audio?: InputRtpAudioOptions;\n  required?: bool;\n  offset_ms?: f64;\n}\n'})}),"\n",(0,t.jsxs)(r.p,{children:["Parameters for an input stream from RTP source. At least one of ",(0,t.jsx)(r.code,{children:"video"})," and ",(0,t.jsx)(r.code,{children:"audio"})," has to be defined."]}),"\n",(0,t.jsx)(r.h4,{id:"properties",children:"Properties"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"port"})," - UDP port or port range on which the compositor should listen for the stream."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"transport_protocol"})," - Transport protocol.","\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:'"udp"'})," - UDP protocol."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:'"tcp_server"'})," - TCP protocol where LiveCompositor is the server side of the connection."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"video"})," - Parameters of a video source included in the RTP stream."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"audio"})," - Parameters of an audio source included in the RTP stream."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"required"})," - (",(0,t.jsxs)(r.strong,{children:["default=",(0,t.jsx)(r.code,{children:"false"})]}),") If input is required and the stream is not delivered on time, then LiveCompositor will delay producing output frames."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"offset_ms"})," - Offset in milliseconds relative to the pipeline start (start request). If the offset is not defined then the stream will be synchronized based on the delivery time of the initial frames."]}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"inputrtpvideooptions",children:"InputRtpVideoOptions"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-typescript",children:'type InputRtpVideoOptions = {\n  codec?: "h264";\n}\n'})}),"\n",(0,t.jsx)(r.h4,{id:"properties-1",children:"Properties"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"codec"})," - (",(0,t.jsxs)(r.strong,{children:["default=",(0,t.jsx)(r.code,{children:'"h264"'})]}),") Video codec.","\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:'"h264"'})," - H264 video."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"inputrtpaudiooptions",children:"InputRtpAudioOptions"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-typescript",children:'type InputRtpAudioOptions = {\n  codec?: "opus";\n  forward_error_correction?: bool;\n}\n'})}),"\n",(0,t.jsx)(r.h4,{id:"properties-2",children:"Properties"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"codec"})," - (",(0,t.jsxs)(r.strong,{children:["default=",(0,t.jsx)(r.code,{children:'"opus"'})]}),") Audio codec.","\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:'"opus"'})," - Opus audio."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"forward_error_correction"})," - (",(0,t.jsxs)(r.strong,{children:["default=",(0,t.jsx)(r.code,{children:"false"})]}),") Specifies whether the stream uses forward error correction. It's specific for Opus codec. For more information, check out ",(0,t.jsx)(r.a,{href:"https://datatracker.ietf.org/doc/html/rfc6716#section-2.1.7",children:"RFC"}),"."]}),"\n"]})]})}function a(e={}){const{wrapper:r}={...(0,i.a)(),...e.components};return r?(0,t.jsx)(r,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},1151:(e,r,n)=>{n.d(r,{Z:()=>d,a:()=>s});var t=n(7294);const i={},o=t.createContext(i);function s(e){const r=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function d(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(o.Provider,{value:r},e.children)}}}]);